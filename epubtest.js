import "dotenv/config";
import { EPub } from "epub2";
import AdmZip from "adm-zip";
import { GoogleGenerativeAI } from "@google/generative-ai";
import OpenAI from "openai";
import * as cheerio from "cheerio";
import path from "path";
import { fileURLToPath } from "url";
import Queue from "better-queue";
import fs from "fs";
import pkg from "natural";
const { NGrams, WordTokenizer } = pkg;

// =================== 1. ESM ç¯å¢ƒå…¼å®¹è®¾ç½® ===================

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const logDir = path.resolve(__dirname, "log");
if (!fs.existsSync(logDir)) {
    fs.mkdirSync(logDir);
}

const writeLog = (type, content) => {
    const timestamp = new Date().toLocaleString();
    const logFile = path.join(
        logDir,
        `translation_${new Date().toISOString().split("T")[0]}.log`,
    );
    const entry = `\n[${timestamp}] [${type}]\n${content}\n${"=".repeat(50)}\n`;
    fs.appendFileSync(logFile, entry, "utf8");
};

// =================== 2. æ ¸å¿ƒè®¾ç½® ===================

const INPUT_FILE_NAME =
    "The Essays of Warren Buffett Lessons for Corporate America, Fourth Edition (Cunningham, Lawrence A. Buffett, Warren E.) (Z-Library).epub";

const CURRENT_PROVIDER = "qwen";
const TEST_MODE_LIMIT = null;

const CONFIG = {
    targetLanguage: "Chinese (Simplified)",
    gemini: {
        apiKey: process.env.GEMINI_API_KEY,
        modelName: "gemini-2.5-pro",
        concurrency: 1,
    },
    qwen: {
        apiKey: process.env.QWEN_API_KEY,
        baseURL: "https://dashscope.aliyuncs.com/compatible-mode/v1",
        modelName: "qwen3-max",
        concurrency: 5,
    },
    mimo: {
        apiKey: process.env.MIMO_API_KEY,
        baseURL: "https://api.xiaomimimo.com/v1",
        modelName: "mimo-v2-flash",
        concurrency: 5,
    },
};

// =================== 3. ç¿»è¯‘é£æ ¼ ===================

const STYLE_GUIDE = `
TRANSLATION STYLE GUIDE (Target: Chinese Simplified):
1. **Rephrase**: Natural Chinese (Xin Da Ya / ä¿¡è¾¾é›…).
2. **Split Long Sentences**: Break down long English clauses.
3. **Tone**: Professional, insightful.
4. **Vocabulary**: Use appropriate idioms (Chengyu) where natural.
5. **No Translationese**: Avoid passive voice (e.g., limit usage of "è¢«").
HEADING FORMATTING RULES:
1. **Consistency**: Table of Contents must match Main Body.
`;

// =================== 4. AI åˆå§‹åŒ–ä¸è°ƒç”¨ ===================

const fileInfo = path.parse(INPUT_FILE_NAME);
const activeModelName = CONFIG[CURRENT_PROVIDER].modelName.replace(
    /[\/\\]/g,
    "-",
);

const inputPath = path.resolve(__dirname, INPUT_FILE_NAME);
const outputPath = path.resolve(
    __dirname,
    `${fileInfo.name}_${activeModelName}.epub`,
);

let geminiModel, qwenClient, mimoClient;

const initClient = () => {
    if (CURRENT_PROVIDER === "gemini") {
        const genAI = new GoogleGenerativeAI(CONFIG.gemini.apiKey);
        geminiModel = genAI.getGenerativeModel({
            model: CONFIG.gemini.modelName,
        });
    } else {
        const client = new OpenAI({
            apiKey: CONFIG[CURRENT_PROVIDER].apiKey,
            baseURL: CONFIG[CURRENT_PROVIDER].baseURL,
        });
        if (CURRENT_PROVIDER === "qwen") qwenClient = client;
        else mimoClient = client;
    }
};

const callAI = async (
    userContent,
    systemInstruction,
    forceJsonMode = false,
) => {
    if (!userContent?.trim()) return "";
    writeLog(
        "REQUEST",
        `SYSTEM:\n${systemInstruction}\n\nUSER:\n${userContent}`,
    );

    try {
        let responseText = "";

        if (CURRENT_PROVIDER === "gemini") {
            const result = await geminiModel.generateContent(
                `${systemInstruction}\n\nUser Input:\n${userContent}`,
            );
            responseText = (await result.response).text().trim();
        } else {
            const client =
                CURRENT_PROVIDER === "qwen" ? qwenClient : mimoClient;
            const options = {
                model: CONFIG[CURRENT_PROVIDER].modelName,
                messages: [
                    { role: "system", content: systemInstruction },
                    { role: "user", content: userContent },
                ],
                ...(forceJsonMode && {
                    response_format: { type: "json_object" },
                }),
            };
            const completion = await client.chat.completions.create(options);
            responseText = completion.choices[0].message.content.trim();
        }

        writeLog("RESPONSE", responseText);
        return responseText;
    } catch (e) {
        writeLog("ERROR", `callAI Failed: ${e.stack || e.message}`);
        throw e;
    }
};

const extractHeading = (htmlContent) => {
    const $ = cheerio.load(htmlContent, {
        xmlMode: true,
        decodeEntities: false,
    });
    let heading = $("h1, h2").first();
    if (heading.length > 0) return heading.text().replace(/\s+/g, " ").trim();
    const titleTag = $("title").text();
    return titleTag ? titleTag.trim() : null;
};

// =================== 5. Agent è§„åˆ’æ¨¡å— ===================

const planTranslationOrder = async (chapters) => {
    console.log("ğŸ•µï¸ Agent is analyzing book structure...");

    const simplifiedChapters = chapters.map((ch) => ({
        id: ch.id,
        title: ch.title,
    }));

    const agentPrompt = `
You are a "Translation Strategy Agent".

I have an EPUB book to translate.

GOAL: Filter and reorder the processing list based on these strict rules:

1. **IDENTIFY TOC (Action: Flag)**:
- Find the chapter that serves as the "Table of Contents" or "Contents" page. 
- If contents chapter exists, in the output JSON, set "tocId" to its ID, otherwise set "tocId" to null.

2. **FILTER & REMOVE (Strict Exclusion)**: 
- From the final "order" list, **COMPLETELY REMOVE** any items identified as: "Table of Contents", "Contents", "Index", "Search Terms", or "Bibliography".
- **Crucial Rule**: Even if you identify a chapter as the TOC for the "tocId" field, you must **NOT** include its ID in the "order" array. The "order" list should contain only translatable content.

3. **MAIN CONTENT FIRST (Priority 1)**: 
- Core chapters (e.g., "Chapter 1", "The Rise of VISA", "Part I").
- Translating these first builds the context glossary.

4. **FRONT/BACK MATTER LAST (Priority 2)**: 
- "Preface", "Introduction", "Foreword", "Copyright", "Dedication", "About the Author", "Acknowledgments".

REASON: Main content provides the necessary context to translate the introductory and administrative sections accurately later.

INPUT: A JSON list of chapters.
OUTPUT: A JSON object containing a single array "order" with the "id"s sorted in the best processing order, excluding the forbidden categories.

OUTPUT: A JSON object:
{
    "tocId": "id_of_toc_chapter_or_null",
    "order": ["chapter_01", "chapter_02", ...]
}`;

    let attempts = 0;

    while (attempts < 3) {
        try {
            const responseText = await callAI(
                JSON.stringify(simplifiedChapters),
                agentPrompt,
                true,
            );

            const result = JSON.parse(
                responseText.replace(/```json|```/g, "").trim(),
            );

            const chapterMap = new Map(chapters.map((c) => [c.id, c]));

            const ordered = result.order
                .filter((id) => chapterMap.has(id))
                .map((id) => {
                    const ch = chapterMap.get(id);
                    if (id === result.tocId) ch.isTOC = true;
                    chapterMap.delete(id);
                    return ch;
                });

            return {
                sorted: [...ordered, ...chapterMap.values()],
                tocId: result.tocId,
            };
        } catch (e) {
            attempts++;
            writeLog(
                "ERROR",
                `Agent Plan Attempt ${attempts} Failed: ${e.stack || e.message}`,
            );
            if (attempts >= 3) return { sorted: chapters, tocId: null };
            await new Promise((r) => setTimeout(r, 2000));
        }
    }
};

// =================== 6. æœ¯è¯­è¡¨ç”Ÿæˆæ¨¡å— ===================

const cleanText = (htmlContent) => {
    const $ = cheerio.load(htmlContent);
    const text = $.text();
    return text.replace(/\s+/g, " ").trim();
};

const getContext = (text, term, window = 40) => {
    try {
        const index = text.toLowerCase().indexOf(term.toLowerCase());
        if (index === -1) return "";
        const start = Math.max(0, index - window);
        const end = Math.min(text.length, index + term.length + window);
        return `...${text.slice(start, end).replace(/\s+/g, " ").trim()}...`;
    } catch (e) {
        return "";
    }
};

const getMostCommonNGrams = (words, n, topK) => {
    const ngrams = NGrams.ngrams(words, n).map((g) => g.join(" "));
    const counts = ngrams.reduce((acc, val) => {
        acc[val] = (acc[val] || 0) + 1;
        return acc;
    }, {});
    return Object.entries(counts)
        .sort((a, b) => b[1] - a[1])
        .slice(0, topK);
};

const generateInitialGlossary = async (chapterMap) => {
    console.log("\nğŸ“Š Step 3: Generating Initial Glossary...");
    let glossary = {};
    try {
        console.log("    - Reading and cleaning book content...");
        let fullText = "";
        for (const chapter of chapterMap.values()) {
            fullText += cleanText(chapter.html) + " ";
        }
        console.log("    - Tokenizing and calculating N-Grams...");
        const tokenizer = new WordTokenizer();
        const words = tokenizer
            .tokenize(fullText.toLowerCase())
            .filter(
                (w) =>
                    w.length > 1 &&
                    !/^(the|and|a|of|to|in|is|it|that|with|as|for|was)$/.test(
                        w,
                    ),
            );
        const biGrams = getMostCommonNGrams(words, 2, 25);
        const triGrams = getMostCommonNGrams(words, 3, 25);
        const formatList = (list) =>
            list.map(([term, count]) => ({
                term: term,
                context: getContext(fullText, term),
                count: count,
            }));
        const payload = JSON.stringify({
            bigrams: formatList(biGrams),
            trigrams: formatList(triGrams),
        });
        console.log("    - Sending candidate terms to AI for selection...");
        const userPrompt = `æˆ‘æƒ³ç¿»è¯‘ä¸€æœ¬ç”µå­ä¹¦ï¼Œç°åœ¨ä½¿ç”¨ n-gram ç®—æ³•åˆæ­¥ç­›é€‰äº†å€™é€‰è¯åˆ—è¡¨ã€‚
è¯·ä½ æŒ‘é€‰å…¶ä¸­å®¹æ˜“å¯¼è‡´ç¿»è¯‘ä¸Šä¸‹æ–‡ç¿»è¯‘ä¸ä¸€è‡´çš„è¯ç»„ï¼Œå°¤å…¶æŒ‘é€‰æ—¥å¸¸ç”Ÿæ´»ä¸­ä¸å¸¸è§çš„ç”¨æ³•ï¼Œä½†æ˜¯é«˜é¢‘å‡ºç°åœ¨ä¹¦ä¸­çš„éƒ¨åˆ†ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºã€‚
è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼Œä¸”ä¸è¦åŒ…å«ä»»ä½•å¤šä½™è¯´æ˜æ–‡å­—ï¼Œåªè¿”å›çº¯ JSON åˆ—è¡¨ï¼š
{
  "glossary": [
    {
        "term": "æœ¯è¯­åç§°",
        "suggested": "å»ºè®®ç¿»è¯‘",
        "reason": "å…¥é€‰ç†ç”±",
        "category": "ç±»åˆ«"
    }
  ]
}
ä¸‹é¢æ˜¯æˆ‘æ•´ç†çš„å€™é€‰é¡¹ï¼š\n${payload}`;
        const systemInstruction =
            "You are a helpful assistant that outputs only JSON.";
        const llmReply = await callAI(userPrompt, systemInstruction, true);

        const parsedResponse = JSON.parse(
            llmReply.replace(/```json|```/g, "").trim(),
        );
        const newTerms = parsedResponse.glossary || [];

        if (Array.isArray(newTerms) && newTerms.length > 0) {
            for (const item of newTerms) {
                if (item.term && item.suggested) {
                    glossary[item.term] = item.suggested;
                }
            }
            console.log(
                `    - âœ… Glossary generated with ${newTerms.length} terms.`,
            );
            writeLog("GLOSSARY", JSON.stringify(newTerms, null, 2));
        } else {
            console.log("    - âš ï¸ No terms were suggested by the AI.");
        }
    } catch (error) {
        console.error("    - âŒ Failed to generate glossary:", error.message);
        writeLog(
            "ERROR",
            `Glossary Generation Failed: ${error.stack || error.message}`,
        );
    }
    console.log("    - Glossary generation step completed.\n");
    return glossary;
};

// =================== 7. ä»»åŠ¡é˜Ÿåˆ—åˆå§‹åŒ– ===================

const batchQueue = new Queue(
    async (task, cb) => {
        const { batch, chapterTitle, $parent, glossary } = task;
        const MAX_ATTEMPTS = 3;

        let attempts = 0;
        let success = false;

        const glossaryMarkdown =
            glossary && Object.keys(glossary).length > 0
                ? `\nGLOSSARY (Strictly follow these translations):\n${Object.entries(
                      glossary,
                  )
                      .map(([en, zh]) => `- ${en}: ${zh}`)
                      .join("\n")}\n`
                : "";

        while (!success && attempts < MAX_ATTEMPTS) {
            try {
                attempts++;

                const batchInput = batch
                    .map((n) => `<node id="${n.id}">${n.content}</node>`)
                    .join("\n");

                const prompt = `
TASK: Translate the content of each <node> into ${CONFIG.targetLanguage}.

CONTEXT: Book Chapter "${chapterTitle}".
use glossary information when translating.
${glossaryMarkdown}
${STYLE_GUIDE}

ğŸ›‘ RULES:
1. Return each node as: <node id="node_x">translated text</node>
2. Keep inline tags (<a>, <strong>, </node> etc.) intact.
                `;

                const rawResponse = await callAI(batchInput, prompt, false);

                for (const node of batch) {
                    const nodeRegex = new RegExp(
                        `<node id="${node.id}">([\\s\\S]*?)<\/node>`,
                        "i",
                    );
                    const match = rawResponse.match(nodeRegex);
                    if (match && match[1]) {
                        $parent(`[data-t-id="${node.id}"]`)
                            .html(match[1].trim())
                            .removeAttr("data-t-id");
                    }
                }

                success = true;
                cb(null);
            } catch (e) {
                writeLog(
                    "ERROR",
                    `Batch Queue Attempt ${attempts} Failed: ${
                        e.stack || e.message
                    }`,
                );
                if (attempts >= MAX_ATTEMPTS) cb(e);
                else await new Promise((r) => setTimeout(r, 2000));
            }
        }
    },
    { concurrent: CONFIG[CURRENT_PROVIDER].concurrency, maxRetries: 0 },
);

// =================== 8. ç¿»è¯‘ HTML å†…å®¹ ===================
const translateHtmlContent = async (htmlContent, chapterTitle, glossary) => {
    const $ = cheerio.load(htmlContent, {
        xmlMode: true,
        decodeEntities: false,
    });
    const nodesToTranslate = [];
    $("p, li, h1, h2, h3, h4, h5, h6, caption, title").each((i, el) => {
        const $el = $(el);
        const originalHtml = $el.html().trim();
        if (originalHtml) {
            const nodeId = `node_${i}`;
            $el.attr("data-t-id", nodeId);
            nodesToTranslate.push({ id: nodeId, content: originalHtml });
        }
    });

    if (nodesToTranslate.length === 0) return $.html();
    const BATCH_SIZE_LIMIT = 5000;

    const processInBatches = async (nodeList) => {
        const batches = [];
        let currentBatch = [];
        let currentLength = 0;
        for (const node of nodeList) {
            if (
                currentLength + node.content.length > BATCH_SIZE_LIMIT &&
                currentBatch.length > 0
            ) {
                batches.push(currentBatch);
                currentBatch = [];
                currentLength = 0;
            }
            currentBatch.push(node);
            currentLength += node.content.length;
        }
        if (currentBatch.length > 0) batches.push(currentBatch);

        const promises = batches.map((batch) => {
            return new Promise((resolve) => {
                batchQueue
                    .push({ batch, chapterTitle, $parent: $, glossary })
                    .on("finish", () => resolve())
                    .on("failed", (err) => {
                        writeLog("ERROR", `Batch Task Failed: ${err?.message}`);
                        resolve();
                    });
            });
        });
        await Promise.all(promises);
    };

    await processInBatches(nodesToTranslate);

    let retryRound = 1;
    const MAX_RETRY_ROUNDS = 3;

    while (retryRound <= MAX_RETRY_ROUNDS) {
        const failedNodes = [];
        $("[data-t-id]").each((_, el) => {
            failedNodes.push({
                id: $(el).attr("data-t-id"),
                content: $(el).html(),
            });
        });

        if (failedNodes.length === 0) break;

        console.log(
            `    - âš ï¸ Retrying ${failedNodes.length} failed nodes (Round ${retryRound}/${MAX_RETRY_ROUNDS})...`,
        );

        writeLog(
            "RETRY_INFO",
            `Round ${retryRound} - Retrying nodes:\n${failedNodes.map((n) => `ID: ${n.id} | Content: ${n.content.substring(0, 100)}...`).join("\n")}`,
        );

        await processInBatches(failedNodes);
        retryRound++;
    }

    $("[data-t-id]").removeAttr("data-t-id");
    return $.html();
};

// =================== 9. æ ¸å¿ƒæ­¥éª¤å‡½æ•° ===================

async function performTranslation(sortedChapters, chapterMap, glossary) {
    console.log("\nâœï¸ Step 4: Translating Book Content...");
    const chaptersToProcess = sortedChapters.slice(
        0,
        TEST_MODE_LIMIT || sortedChapters.length,
    );
    for (let i = 0; i < chaptersToProcess.length; i++) {
        const ch = chaptersToProcess[i];
        if (ch.isTOC) continue;
        console.log(
            `ğŸš€ [${i + 1}/${chaptersToProcess.length}] Processing Chapter: "${ch.title}"`,
        );
        try {
            const translatedHtml = await translateHtmlContent(
                ch.html,
                ch.title,
                glossary,
            );
            if (chapterMap.has(ch.id))
                chapterMap.get(ch.id).html = translatedHtml;
        } catch (e) {
            writeLog(
                "ERROR",
                `Chapter "${ch.title}" Translation Failed: ${e.stack || e.message}`,
            );
        }
    }
}

async function standardizeHeadingFormats(chapterMap) {
    console.log("\nğŸ§ Step 5: Standardizing Heading Formats...");
    const headingSelectors = "h1, h2, h3, h4, h5, h6";
    const uniqueHeadings = new Set();
    for (const data of chapterMap.values()) {
        const $temp = cheerio.load(data.html, {
            xmlMode: true,
            decodeEntities: false,
        });
        $temp(headingSelectors).each((_, el) => {
            const txt = $temp(el).text().trim();
            if (txt) uniqueHeadings.add(txt);
        });
    }
    let corrections = {};
    if (uniqueHeadings.size > 0) {
        const prompt = `
You are a professional copy editor. Standardize chapter headings. Please output your response in JSON format.
RULES: "Chapter X" -> "ç¬¬Xç« " (Arabic numerals).
Example Input: ["ç¬¬ä¸€ç«  å¼€å§‹", "ç¬¬2ç«  ä¸­é—´", "Conclusion", "ç¬¬3ç« <br/><br/>ç»“æŸ"]
Example Output: { "ç¬¬ä¸€ç«  å¼€å§‹": "ç¬¬1ç«  å¼€å§‹", "ç¬¬2ç«  ä¸­é—´": "ç¬¬2ç«  ä¸­é—´", "Conclusion": "Conclusion", "ç¬¬3ç« <br/><br/>ç»“æŸ": "ç¬¬3ç«  ç»“æŸ"}
        `;
        let attempts = 0;
        while (attempts < 3) {
            try {
                const responseText = await callAI(
                    JSON.stringify(Array.from(uniqueHeadings)),
                    prompt,
                    true,
                );
                corrections = JSON.parse(
                    responseText.replace(/```json|```/g, "").trim(),
                );
                break;
            } catch (e) {
                attempts++;
                writeLog(
                    "ERROR",
                    `Heading Standardize Attempt ${attempts} Failed: ${e.stack || e.message}`,
                );
                if (attempts >= 3) break;
                await new Promise((r) => setTimeout(r, 2000));
            }
        }
    }
    for (const data of chapterMap.values()) {
        const $html = cheerio.load(data.html, {
            xmlMode: true,
            decodeEntities: false,
        });
        let changed = false;
        $html(headingSelectors).each((_, el) => {
            const original = $html(el).text().trim();
            const corrected = corrections[original] || original;
            if (original !== corrected) {
                $html(el).text(corrected);
                changed = true;
            }
        });
        if (changed) data.html = $html.html();
    }
}

async function synchronizeTocHtml(chapterMap, tocId) {
    if (!tocId || !chapterMap.has(tocId)) return;
    console.log("\nğŸ”— Step 6: Synchronizing HTML TOC...");
    try {
        const tocData = chapterMap.get(tocId);
        const $toc = cheerio.load(tocData.html, {
            xmlMode: true,
            decodeEntities: false,
        });
        const allChapters = Array.from(chapterMap.values());
        $toc("a[href]").each((_, el) => {
            const $a = $toc(el);
            const href = $a.attr("href");
            const targetChapter = allChapters.find((ch) =>
                href.includes(path.basename(ch.href)),
            );
            if (targetChapter && targetChapter.id !== tocId) {
                const $temp = cheerio.load(targetChapter.html);
                const translatedTitle = $temp("h1, h2, h3")
                    .first()
                    .text()
                    .trim();
                if (translatedTitle) $a.text(translatedTitle);
            }
        });
        tocData.html = $toc.html();
    } catch (e) {
        writeLog("ERROR", `HTML TOC Sync Failed: ${e.stack || e.message}`);
    }
}

async function synchronizeNcx(chapterMap, zipEntries) {
    console.log("\nğŸ”— Step 7: Synchronizing NCX Metadata...");
    try {
        const ncxEntry = zipEntries.find((e) => e.entryName.endsWith(".ncx"));
        if (!ncxEntry) return { ncxEntry: null, ncxContent: "" };
        const ncxContent = ncxEntry.getData().toString("utf8");
        const $ncx = cheerio.load(ncxContent, {
            xmlMode: true,
            decodeEntities: false,
        });
        const headingSelectors = "h1, h2, h3, h4, h5, h6";
        for (const [id, data] of chapterMap) {
            const $html = cheerio.load(data.html, {
                xmlMode: true,
                decodeEntities: false,
            });
            const firstTitle = $html(headingSelectors).first().text().trim();
            if (firstTitle) {
                let $nav = $ncx(`navPoint[id="${id}"]`);
                if ($nav.length === 0) {
                    const fn = path.basename(data.href);
                    $nav = $ncx(`navPoint`).filter((_, el) =>
                        $ncx(el).find("content").attr("src")?.includes(fn),
                    );
                }
                if ($nav.length > 0)
                    $nav.find("navLabel > text").first().text(firstTitle);
            }
        }
        return { ncxEntry, ncxContent: $ncx.xml() };
    } catch (e) {
        writeLog("ERROR", `NCX Sync Failed: ${e.stack || e.message}`);
        return { ncxEntry: null, ncxContent: "" };
    }
}

async function saveEpub(zip, chapterMap, ncxEntry, ncxContent) {
    console.log(`\nğŸ’¾ Step 8: Finalizing and Saving...`);
    try {
        for (const [id, data] of chapterMap.entries()) {
            zip.updateFile(data.entryName, Buffer.from(data.html, "utf8"));
        }
        if (ncxEntry && ncxContent)
            zip.updateFile(ncxEntry.entryName, Buffer.from(ncxContent, "utf8"));
        zip.writeZip(outputPath);
        console.log(`ğŸ‰ Done! Output: ${path.basename(outputPath)}`);
    } catch (e) {
        writeLog("ERROR", `Save EPUB Failed: ${e.stack || e.message}`);
        throw e;
    }
}

// =================== 10. ä¸»æµç¨‹ ===================
const main = async () => {
    initClient();
    console.log(`\n========================================`);
    console.log(`ğŸ“– Input: ${path.basename(inputPath)}`);
    console.log(`========================================\n`);
    try {
        // Step 1: è¯»å– EPUB å†…å®¹
        console.log("ğŸ“– Step 1: Reading EPUB Content...");
        const zip = new AdmZip(inputPath);
        const epub = await EPub.createAsync(inputPath);
        const zipEntries = zip.getEntries();
        const chapterMap = new Map();
        const rawChapters = epub.flow.map((chapter) => {
            const zipEntry = zipEntries.find((e) =>
                decodeURIComponent(e.entryName).endsWith(
                    decodeURIComponent(chapter.href),
                ),
            );
            const html = zipEntry ? zipEntry.getData().toString("utf8") : "";
            const data = {
                ...chapter,
                html,
                entryName: zipEntry?.entryName,
                title: chapter.title || extractHeading(html) || "Untitled",
            };
            if (data.entryName) chapterMap.set(data.id, data);
            return data;
        });

        // Step 2: åˆ¶å®šç¿»è¯‘è®¡åˆ’
        console.log("ğŸ“– Step 2: Planning Translation Order...");
        const { sorted: sortedChapters, tocId } =
            await planTranslationOrder(rawChapters);

        // Step 3: ç”Ÿæˆæœ¯è¯­è¡¨
        const glossary = await generateInitialGlossary(chapterMap);

        // Step 4: æ‰§è¡Œç¿»è¯‘
        await performTranslation(sortedChapters, chapterMap, glossary);

        // Step 5: æ ‡é¢˜æ ‡å‡†åŒ–
        await standardizeHeadingFormats(chapterMap);

        // Step 6: åŒæ­¥ HTML ç›®å½•
        await synchronizeTocHtml(chapterMap, tocId);

        // Step 7: åŒæ­¥ NCX å…ƒæ•°æ®
        const { ncxEntry, ncxContent } = await synchronizeNcx(
            chapterMap,
            zipEntries,
        );

        // Step 8: ä¿å­˜æ–‡ä»¶
        await saveEpub(zip, chapterMap, ncxEntry, ncxContent);
    } catch (e) {
        writeLog("ERROR", `Main Process Fatal Error: ${e.stack || e.message}`);
        console.error("Fatal error occurred. Check logs for details.");
    }
};

main();
